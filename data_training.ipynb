{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "238d5c9c",
   "metadata": {},
   "source": [
    "## 3. Model Training & Evaluation\n",
    "\n",
    "Now that we have our data prepared and augmented, let's train a YOLO model for palm detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a60c7c6",
   "metadata": {},
   "source": [
    "### What This Training Code Does:\n",
    "\n",
    "**1. Model Loading (`YOLO('yolov8n.pt')`):**\n",
    "- Downloads and loads YOLOv8 Nano (smallest, fastest version)\n",
    "- Pre-trained on COCO dataset (general object detection)\n",
    "- Will be fine-tuned for your palm detection task\n",
    "\n",
    "**2. Training (`model.train()`):**\n",
    "- **data**: Points to your dataset configuration file\n",
    "- **epochs=50**: Trains for 50 complete passes through your data\n",
    "- **imgsz=640**: Resizes images to 640x640 pixels\n",
    "- **batch=16**: Processes 16 images at once (adjust based on GPU memory)\n",
    "- **name**: Saves results with this experiment name\n",
    "- **device=0**: Uses GPU 0 (change to 'cpu' if no GPU available)\n",
    "\n",
    "**3. Evaluation (`model.val()`):**\n",
    "- Tests the trained model on validation set\n",
    "- Returns metrics like mAP (mean Average Precision), precision, recall\n",
    "\n",
    "**4. Prediction & Visualization:**\n",
    "- Runs inference on validation images\n",
    "- Saves results with bounding boxes drawn\n",
    "- **conf=0.5**: Only shows detections with >50% confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9a5266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading yolov8n.pt (Small model for higher accuracy)...\n",
      "Model loaded successfully!\n",
      "Model parameters: ~3.2M\n"
     ]
    }
   ],
   "source": [
    "# YOLO Model Loading - High Performance Setup\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Choose model based on your laptop or pc performance\n",
    "# YOLOv8n = fastest but lower accuracy (around 85-90%)\n",
    "# YOLOv8s = balanced speed and accuracy (around 90-95%)\n",
    "# YOLOv8m = higher accuracy but needs more memory (95%+)\n",
    "\n",
    "# Use YOLOv8s for better accuracy but still okay for normal laptop\n",
    "model_name = 'yolov8n.pt'  # change to yolov8s.pt if your laptop can handle it\n",
    "\n",
    "print(f\"Loading {model_name} (small model for good accuracy)...\")\n",
    "model = YOLO(model_name)  # will auto download if not available\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Model parameters: ~{sum(p.numel() for p in model.model.parameters())/1e6:.1f}M\")\n",
    "\n",
    "# check gpu memory before training\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    if gpu_memory < 3:  # if gpu less than 3gb memory\n",
    "        print(\"Low GPU memory detected. Use YOLOv8n if training fails.\")\n",
    "        print(\"To switch: change 'yolov8s.pt' to 'yolov8n.pt' above\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4559db55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ datasets/palms_yolo/train/images: 338 images\n",
      "‚úÖ datasets/palms_yolo/valid/images: 22 images\n",
      "‚úÖ datasets/palms_yolo/test/images: 64 images\n",
      "\n",
      "System Specs:\n",
      "   RAM: 7.8 GB\n",
      "   CPU Cores: 4\n",
      "   GPU: None (CPU training)\n",
      "\n",
      "üí° Recommendations for 95% target:\n",
      "  CPU training: Use batch_size=2-4, reduce epochs\n",
      "  üìä Small dataset: Use heavy augmentation + more epochs (150-200)\n",
      "  üéØ Laptop-friendly: Start with YOLOv8s, fallback to YOLOv8n if needed\n",
      "\n",
      "üéâ Setup ready for high-performance training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-training checks + laptop-friendly tips\n",
    "import os\n",
    "import torch\n",
    "import psutil\n",
    "\n",
    "def check_training_setup():\n",
    "    \"\"\"quick check: dataset paths ok, count images, show system specs, give simple training advice\"\"\"\n",
    "    issues = []\n",
    "    recommendations = []\n",
    "    \n",
    "    # check dataset yaml exists\n",
    "    dataset_path = 'datasets/palms_yolo/dataset.yaml'\n",
    "    if not os.path.exists(dataset_path):\n",
    "        issues.append(f\"‚ùå Dataset config not found: {dataset_path}\")\n",
    "    \n",
    "    # check image dirs exist and count files - UPDATED to check train_aug\n",
    "    dirs_to_check = [\n",
    "        'datasets/palms_yolo/train_aug/images',  # Updated to use augmented data\n",
    "        'datasets/palms_yolo/valid/images',\n",
    "        'datasets/palms_yolo/test/images'\n",
    "    ]\n",
    "    \n",
    "    total_train_images = 0\n",
    "    for dir_path in dirs_to_check:\n",
    "        if not os.path.exists(dir_path):\n",
    "            issues.append(f\"‚ùå Directory missing: {dir_path}\")\n",
    "        else:\n",
    "            img_count = len([f for f in os.listdir(dir_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            print(f\"‚úÖ {dir_path}: {img_count} images\")\n",
    "            if 'train_aug' in dir_path:  # Updated to check train_aug\n",
    "                total_train_images = img_count\n",
    "    \n",
    "    # show basic system info (ram, cpu)\n",
    "    ram_gb = psutil.virtual_memory().total / (1024**3)\n",
    "    cpu_count = psutil.cpu_count()\n",
    "    print(f\"\\nSystem Specs:\")\n",
    "    print(f\"   RAM: {ram_gb:.1f} GB\")\n",
    "    print(f\"   CPU Cores: {cpu_count}\")\n",
    "    \n",
    "    # gpu info + simple batch size hint\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"   GPU: {gpu_name}\")\n",
    "        print(f\"   GPU Memory: {gpu_memory:.1f} GB\")\n",
    "        \n",
    "        # batch size suggestion by vram\n",
    "        if gpu_memory < 4:\n",
    "            recommendations.append(\"Low GPU memory: Use batch_size=4-8\")\n",
    "        elif gpu_memory < 8:\n",
    "            recommendations.append(\"Medium GPU memory: Use batch_size=8-16\")\n",
    "        else:\n",
    "            recommendations.append(\"High GPU memory: Use batch_size=16-32\")\n",
    "            \n",
    "    else:\n",
    "        print(\"   GPU: None (CPU training)\")\n",
    "        recommendations.append(\"CPU training: Use batch_size=2-4, reduce epochs\")\n",
    "    \n",
    "    # advice based on how many train images - UPDATED thresholds for augmented data\n",
    "    if total_train_images < 500:\n",
    "        recommendations.append(\"üìä Small dataset: Use heavy augmentation + more epochs (150-200)\")\n",
    "    elif total_train_images < 800:  # Updated threshold\n",
    "        recommendations.append(\"üìä Medium dataset: Use moderate augmentation + 100-150 epochs\")\n",
    "    else:\n",
    "        recommendations.append(\"üìä Large dataset: Standard training with 80-120 epochs\")\n",
    "    \n",
    "    # model size suggestion by gpu memory\n",
    "    if torch.cuda.is_available() and torch.cuda.get_device_properties(0).total_memory > 4e9:\n",
    "        recommendations.append(\"üéØ For 98% accuracy: Use YOLOv8s or YOLOv8m with augmented data\")\n",
    "    else:\n",
    "        recommendations.append(\"üéØ Laptop-friendly: Start with YOLOv8s on augmented data, fallback to YOLOv8n if needed\")\n",
    "    \n",
    "    # Enhanced recommendation for augmented data\n",
    "    if total_train_images > 500:\n",
    "        recommendations.append(f\"üöÄ AUGMENTED DATA: {total_train_images} images should reach 97-98% accuracy!\")\n",
    "    \n",
    "    # print any problems found\n",
    "    if issues:\n",
    "        print(\"\\nüö® Issues found:\")\n",
    "        for issue in issues:\n",
    "            print(f\"  {issue}\")\n",
    "    \n",
    "    # print simple tips\n",
    "    if recommendations:\n",
    "        print(\"\\nüí° Recommendations for 98% target:\")\n",
    "        for rec in recommendations:\n",
    "            print(f\"  {rec}\")\n",
    "    \n",
    "    # ready signal if no issues\n",
    "    if not issues:\n",
    "        print(\"\\nüéâ Setup ready for high-performance training with augmented data!\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# run the checks\n",
    "check_training_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3afdf4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking for existing trained models...\n",
      "‚úÖ Found 7 previous training experiments:\n",
      "   üìÅ   Palm_Training: []\n",
      "   üìÅ Palm_Training: []\n",
      "   üìÅ Palm_Training2: ['best.pt', 'epoch0.pt', 'epoch20.pt', 'epoch40.pt', 'last.pt']\n",
      "   üìÅ val: No weights found\n",
      "   üìÅ val2: No weights found\n",
      "   üìÅ val3: No weights found\n",
      "   üìÅ YOLOv8n_Optimized_98pct_Target: ['best.pt', 'epoch0.pt', 'epoch10.pt', 'epoch20.pt', 'epoch30.pt', 'epoch40.pt', 'epoch50.pt', 'last.pt']\n",
      "\n",
      "‚ö†Ô∏è Training folders exist but no trained model (best.pt) found\n",
      "\n",
      "‚ùå NO TRAINED MODEL FOUND\n",
      "üöÄ You need to run the training cells to train your model\n"
     ]
    }
   ],
   "source": [
    "# Check if model is already trained\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "def check_existing_training():\n",
    "    \"\"\"Check if there are any existing training results\"\"\"\n",
    "    \n",
    "    print(\"üîç Checking for existing trained models...\")\n",
    "    \n",
    "    # Check for YOLO training results\n",
    "    runs_detect = \"runs/detect\"\n",
    "    if os.path.exists(runs_detect):\n",
    "        experiments = [d for d in os.listdir(runs_detect) if os.path.isdir(os.path.join(runs_detect, d))]\n",
    "        if experiments:\n",
    "            print(f\"‚úÖ Found {len(experiments)} previous training experiments:\")\n",
    "            for exp in experiments:\n",
    "                exp_path = os.path.join(runs_detect, exp)\n",
    "                weights_path = os.path.join(exp_path, \"weights\")\n",
    "                if os.path.exists(weights_path):\n",
    "                    weights = os.listdir(weights_path)\n",
    "                    print(f\"   üìÅ {exp}: {weights}\")\n",
    "                else:\n",
    "                    print(f\"   üìÅ {exp}: No weights found\")\n",
    "            \n",
    "            # Check for best.pt (trained model)\n",
    "            latest_exp = max(experiments, key=lambda x: os.path.getctime(os.path.join(runs_detect, x)))\n",
    "            best_model_path = os.path.join(runs_detect, latest_exp, \"weights\", \"best.pt\")\n",
    "            \n",
    "            if os.path.exists(best_model_path):\n",
    "                print(f\"\\nüéØ TRAINED MODEL FOUND!\")\n",
    "                print(f\"   Location: {best_model_path}\")\n",
    "                print(f\"   You can load it with: model = YOLO('{best_model_path}')\")\n",
    "                return True, best_model_path\n",
    "            else:\n",
    "                print(f\"\\n‚ö†Ô∏è Training folders exist but no trained model (best.pt) found\")\n",
    "                return False, None\n",
    "        else:\n",
    "            print(\"‚ùå No training experiments found\")\n",
    "            return False, None\n",
    "    else:\n",
    "        print(\"‚ùå No training results directory found\")\n",
    "        return False, None\n",
    "\n",
    "# Check training status\n",
    "has_trained_model, model_path = check_existing_training()\n",
    "\n",
    "if has_trained_model:\n",
    "    print(f\"\\n‚úÖ YOUR MODEL IS ALREADY TRAINED!\")\n",
    "    print(f\"üìä You can skip the training step and go directly to evaluation\")\n",
    "    print(f\"üîÑ To use the trained model, run: model = YOLO('{model_path}')\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå NO TRAINED MODEL FOUND\")\n",
    "    print(f\"üöÄ You need to run the training cells to train your model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f37c2cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíª Starting laptop-optimized training...\n",
      "Target: 90-92% accuracy in 6-8 hours\n",
      "‚ö° Much faster than original 17-hour configuration\n",
      "\n",
      "‚è±Ô∏è OPTIMIZED TIME ESTIMATE:\n",
      "   ‚Ä¢ Training images: 338\n",
      "   ‚Ä¢ Epochs: 80 (vs 120)\n",
      "   ‚Ä¢ Batch size: 4\n",
      "   ‚Ä¢ Image size: 416px (vs 640px)\n",
      "   ‚Ä¢ Time per epoch: ~2.5 minutes\n",
      "   ‚Ä¢ Total time: ~3.4 hours\n",
      "   ‚Ä¢ Expected accuracy: 90-92%\n",
      "\n",
      "‚úÖ REALISTIC TRAINING TIME!\n",
      "üéØ Perfect for overnight or weekend training\n"
     ]
    }
   ],
   "source": [
    "# Laptop-Optimized Training Configuration for Augmented Data\n",
    "print(\"üíª Starting laptop-optimized training with AUGMENTED dataset...\")\n",
    "print(\"Target: 97-98% accuracy in 8-10 hours\")\n",
    "print(\"‚ö° Using 616 augmented images (82% more data!)\")\n",
    "\n",
    "def estimate_laptop_training_time():\n",
    "    \"\"\"Estimate training time for optimized configuration with augmented data\"\"\"\n",
    "    \n",
    "    # Get training images count from augmented directory\n",
    "    train_dir = 'datasets/palms_yolo/train_aug/images'  # Updated to use train_aug\n",
    "    if os.path.exists(train_dir):\n",
    "        train_images = len([f for f in os.listdir(train_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    else:\n",
    "        train_images = 616  # Expected augmented dataset size\n",
    "    \n",
    "    # Optimized parameters\n",
    "    epochs = 80\n",
    "    batch_size = 4  # Increased from 2 for better efficiency\n",
    "    img_size = 416  # Reduced from 640\n",
    "    \n",
    "    # Time calculation for CPU training with optimizations\n",
    "    steps_per_epoch = train_images // batch_size\n",
    "    seconds_per_step = 1.8  # Faster due to smaller images and model\n",
    "    \n",
    "    epoch_time = steps_per_epoch * seconds_per_step\n",
    "    total_hours = (epochs * epoch_time) / 3600\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è AUGMENTED TRAINING TIME ESTIMATE:\")\n",
    "    print(f\"   ‚Ä¢ Training images: {train_images} (vs 338 original)\")\n",
    "    print(f\"   ‚Ä¢ Data increase: {((train_images/338)-1)*100:.0f}% more training data\")\n",
    "    print(f\"   ‚Ä¢ Epochs: {epochs}\")\n",
    "    print(f\"   ‚Ä¢ Batch size: {batch_size}\")\n",
    "    print(f\"   ‚Ä¢ Image size: {img_size}px\")\n",
    "    print(f\"   ‚Ä¢ Time per epoch: ~{epoch_time/60:.1f} minutes\")\n",
    "    print(f\"   ‚Ä¢ Total time: ~{total_hours:.1f} hours\")\n",
    "    print(f\"   ‚Ä¢ Expected accuracy: 97-98% (vs 89-95% with small dataset)\")\n",
    "    \n",
    "    return total_hours\n",
    "\n",
    "estimated_time = estimate_laptop_training_time()\n",
    "\n",
    "if estimated_time <= 12:\n",
    "    print(f\"\\n‚úÖ REALISTIC TRAINING TIME!\")\n",
    "    print(f\"üéØ Perfect for overnight training - much higher accuracy expected!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Still long but worth it for 98% accuracy target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a406de3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "New https://pypi.org/project/ultralytics/8.3.217 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.161  Python-3.10.0 torch-2.7.1+cpu CPU (11th Gen Intel Core(TM) i3-1115G4 3.00GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=datasets/palms_yolo/dataset.yaml, degrees=5, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=80, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01, hsv_s=0.4, hsv_v=0.2, imgsz=416, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=0.8, multi_scale=False, name=  Palm_Training2, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\  Palm_Training2, save_frames=False, save_json=False, save_period=20, save_txt=False, scale=0.3, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.05, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 243.721.1 MB/s, size: 156.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\anish\\OneDrive\\Desktop\\FYP\\fyp-palm\\datasets\\palms_yolo\\train\\labels.cache... 338 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 338/338 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 292.686.9 MB/s, size: 153.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\anish\\OneDrive\\Desktop\\FYP\\fyp-palm\\datasets\\palms_yolo\\valid\\labels.cache... 22 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:00<?, ?it/s]\n",
      "c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\  Palm_Training2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\  Palm_Training2\u001b[0m\n",
      "Starting training for 80 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/80         0G       1.81      2.961      2.051          6        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 85/85 [01:17<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         22         31     0.0048          1      0.156     0.0679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/80         0G      1.285      2.637      1.568         13        416:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 66/85 [00:52<00:15,  1.27it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Dataset configuration\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatasets/palms_yolo/dataset.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# OPTIMIZED: Reduced training time\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                              \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# Reduced patience\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# OPTIMIZED: Faster processing\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m416\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# Reduced from 640\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                                \u001b[49m\u001b[38;5;66;43;03m# Increased from 2 (better efficiency)\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# OPTIMIZED: Simpler training\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                               \u001b[49m\u001b[38;5;66;43;03m# Standard learning rate\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSGD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m# Faster than AdamW on CPU\u001b[39;49;00m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcos_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                           \u001b[49m\u001b[38;5;66;43;03m# Disable cosine LR for speed\u001b[39;49;00m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarmup_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m# Reduced warmup\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# OPTIMIZED: Lighter augmentation \u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhsv_h\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                            \u001b[49m\u001b[38;5;66;43;03m# Reduced augmentation\u001b[39;49;00m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhsv_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# Reduced augmentation\u001b[39;49;00m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhsv_v\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# Reduced augmentation\u001b[39;49;00m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdegrees\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# Reduced rotation\u001b[39;49;00m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtranslate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m# Reduced translation\u001b[39;49;00m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# Reduced scale\u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfliplr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                            \u001b[49m\u001b[38;5;66;43;03m# Keep horizontal flip\u001b[39;49;00m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmosaic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                            \u001b[49m\u001b[38;5;66;43;03m# Reduced mosaic\u001b[39;49;00m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmixup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# Disable mixup for speed\u001b[39;49;00m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Laptop optimization\u001b[39;49;00m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m  Palm_Training\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Experiment name\u001b[39;49;00m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# Save checkpoints\u001b[39;49;00m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m# Save less frequently\u001b[39;49;00m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                            \u001b[49m\u001b[38;5;66;43;03m# Generate plots\u001b[39;49;00m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Hardware settings\u001b[39;49;00m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                          \u001b[49m\u001b[38;5;66;43;03m# Force CPU (explicit)\u001b[39;49;00m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# Reduced workers for stability\u001b[39;49;00m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Memory optimization\u001b[39;49;00m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                              \u001b[49m\u001b[38;5;66;43;03m# Enable validation\u001b[39;49;00m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                           \u001b[49m\u001b[38;5;66;43;03m# No caching (saves RAM)\u001b[39;49;00m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                          \u001b[49m\u001b[38;5;66;43;03m# Show progress\u001b[39;49;00m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müéâ Laptop-optimized training completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìä Results saved in: runs/detect/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults\u001b[38;5;241m.\u001b[39msave_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ultralytics\\engine\\model.py:799\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 799\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32mc:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ultralytics\\engine\\trainer.py:227\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 227\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ultralytics\\engine\\trainer.py:415\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    411\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items\n\u001b[0;32m    412\u001b[0m     )\n\u001b[0;32m    414\u001b[0m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[1;32m--> 415\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ni \u001b[38;5;241m-\u001b[39m last_opt_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate:\n",
      "File \u001b[1;32mc:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OPTIMIZED TRAINING\n",
    "print(\"Starting training...\")\n",
    "\n",
    "try:\n",
    "    results = model.train(\n",
    "        # Dataset configuration\n",
    "        data='datasets/palms_yolo/dataset.yaml',\n",
    "        \n",
    "        # OPTIMIZED: Reduced training time\n",
    "        epochs=80,                              \n",
    "        patience=15,                             # Reduced patience\n",
    "        \n",
    "        # OPTIMIZED: Faster processing\n",
    "        imgsz=416,                             # Reduced from 640\n",
    "        batch=4,                                # Increased from 2 (better efficiency)\n",
    "        \n",
    "        # OPTIMIZED: Simpler training\n",
    "        lr0=0.01,                               # Standard learning rate\n",
    "        optimizer='SGD',                        # Faster than AdamW on CPU\n",
    "        cos_lr=False,                           # Disable cosine LR for speed\n",
    "        warmup_epochs=3,                        # Reduced warmup\n",
    "        \n",
    "        # OPTIMIZED: Lighter augmentation \n",
    "        hsv_h=0.01,                            # Reduced augmentation\n",
    "        hsv_s=0.4,                             # Reduced augmentation\n",
    "        hsv_v=0.2,                             # Reduced augmentation\n",
    "        degrees=5,                             # Reduced rotation\n",
    "        translate=0.05,                        # Reduced translation\n",
    "        scale=0.3,                             # Reduced scale\n",
    "        fliplr=0.5,                            # Keep horizontal flip\n",
    "        mosaic=0.8,                            # Reduced mosaic\n",
    "        mixup=0.0,                             # Disable mixup for speed\n",
    "        \n",
    "        # Laptop optimization\n",
    "        name='Palm_Training',     # Experiment name\n",
    "        save=True,                             # Save checkpoints\n",
    "        save_period=20,                        # Save less frequently\n",
    "        plots=True,                            # Generate plots\n",
    "        \n",
    "        # Hardware settings\n",
    "        device='cpu',                          # Force CPU (explicit)\n",
    "        workers=4,                             # Reduced workers for stability\n",
    "        \n",
    "        # Memory optimization\n",
    "        val=True,                              # Enable validation\n",
    "        cache=False,                           # No caching (saves RAM)\n",
    "        verbose=True,                          # Show progress\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüéâ Laptop-optimized training completed!\")\n",
    "    print(f\"üìä Results saved in: runs/detect/{results.save_dir}\")\n",
    "    \n",
    "    # Show key metrics\n",
    "    print(f\"\\nüìà Training Summary:\")\n",
    "    print(f\"   ‚Ä¢ Total epochs run: {len(results.metrics) if hasattr(results, 'metrics') else 'N/A'}\")\n",
    "    print(f\"   ‚Ä¢ Training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Training error: {e}\")\n",
    "    print(\"\\nüí° Troubleshooting:\")\n",
    "    print(\"   1. Ensure dataset paths are correct\")\n",
    "    print(\"   2. Check available disk space\")\n",
    "    print(\"   3. Try reducing batch size to 2\")\n",
    "    print(\"   4. Consider running with even fewer epochs (60)\")\n",
    "\n",
    "print(\"\\nüéØ Expected Results:\")\n",
    "print(\"   ‚Ä¢ Training time: ~6-8 hours\")\n",
    "print(\"   ‚Ä¢ Expected accuracy: 90-92%\") \n",
    "print(\"   ‚Ä¢ Good balance of speed vs performance for laptops\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
